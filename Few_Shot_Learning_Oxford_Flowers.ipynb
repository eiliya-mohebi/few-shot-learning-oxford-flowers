{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In The Name Of GOD\n",
    "#### Developed By Eiliya Mohebi For Educational Purposes (As Part Of Filoger Advanced Computer Vision Course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Library Imports\n",
    "This cell imports necessary libraries such as TensorFlow, NumPy, and others. It also sets the image size and configures GPU memory growth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"âœ… Enabled GPU memory growth.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Prepare Oxford Flowers 102 Dataset\n",
    "The following function downloads the Oxford Flowers 102 dataset, extracts the images from a tar file, downloads the corresponding labels, and organizes the images into class-specific folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_prepare_oxford_flowers102(download_dir=\"oxford_flowers102\"):\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # URLs for the dataset\n",
    "    data_url = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\"\n",
    "    labels_url = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\"\n",
    "\n",
    "    # 1) Download the images tar\n",
    "    tar_path = tf.keras.utils.get_file(\n",
    "        origin=data_url,\n",
    "        fname=\"102flowers.tgz\",\n",
    "        cache_dir=download_dir,\n",
    "        cache_subdir=\"\",\n",
    "        extract=False\n",
    "    )\n",
    "\n",
    "    # 2) Extract the tar into download_dir\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=download_dir)\n",
    "\n",
    "    # 3) Download the labels .mat file\n",
    "    labels_path = tf.keras.utils.get_file(\n",
    "        origin=labels_url,\n",
    "        fname=\"imagelabels.mat\",\n",
    "        cache_dir=download_dir,\n",
    "        cache_subdir=\"\"\n",
    "    )\n",
    "\n",
    "    # 4) Read .mat to get image labels\n",
    "    import scipy.io\n",
    "    mat = scipy.io.loadmat(os.path.join(download_dir, \"imagelabels.mat\"))\n",
    "    labels = mat[\"labels\"][0]\n",
    "\n",
    "    jpg_dir = os.path.join(download_dir, \"jpg\")\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        class_folder = os.path.join(download_dir, f\"class_{label}\")\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "        old_path = os.path.join(jpg_dir, f\"image_{i+1:05d}.jpg\")\n",
    "        new_path = os.path.join(class_folder, f\"image_{i+1:05d}.jpg\")\n",
    "        os.rename(old_path, new_path)\n",
    "\n",
    "    os.rmdir(jpg_dir)\n",
    "\n",
    "    return download_dir\n",
    "\n",
    "\n",
    "base_dir = download_and_prepare_oxford_flowers102()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and Get Image Paths with Labels\n",
    "The following functions perform two key tasks:\n",
    "\n",
    "- **load_image:** Reads an image from disk, resizes it to the defined size, and normalizes the pixel values to the range [0, 1].\n",
    "- **get_image_paths_and_labels:** Walks through the dataset directory structure to retrieve image paths and the corresponding labels (folder names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    \"\"\"Load and resize a single image, normalizing to [0,1].\"\"\"\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def get_image_paths_and_labels(base_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                full_path = os.path.join(root, file)\n",
    "                # Label is the name of the folder containing the image\n",
    "                label = os.path.basename(os.path.dirname(full_path))\n",
    "                image_paths.append(full_path)\n",
    "                labels.append(label)\n",
    "    return image_paths, labels\n",
    "\n",
    "\n",
    "base_dir = \"./oxford_flowers102\"\n",
    "image_paths, labels = get_image_paths_and_labels(base_dir)\n",
    "\n",
    "print(\"Total images found:\", len(image_paths))\n",
    "print(\"Unique classes:\", len(set(labels)))\n",
    "\n",
    "from collections import defaultdict\n",
    "class_to_images = defaultdict(list)\n",
    "for path, label in zip(image_paths, labels):\n",
    "    class_to_images[label].append(path)\n",
    "\n",
    "# Convert to a list of (class_name, list_of_paths)\n",
    "class_names = sorted(list(class_to_images.keys()))\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# Shuffle paths within each class\n",
    "for c in class_names:\n",
    "    random.shuffle(class_to_images[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Episodes for Few-Shot Learning\n",
    "The `create_episode` function creates one episode for few-shot learning. Each episode contains a support set and a query set sampled from a subset of classes. The function selects a few classes (n-way) and for each class picks `k_shot` examples for the support set and a fixed number for the query set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_episode(\n",
    "    class_to_imgs_dict, \n",
    "    class_names, \n",
    "    n_way=3, \n",
    "    k_shot=3, \n",
    "    n_query_per_class=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a single episode with:\n",
    "      - support_x: (n_way * k_shot) images\n",
    "      - support_y: (n_way * k_shot) labels\n",
    "      - query_x:   (n_way * n_query_per_class) images\n",
    "      - query_y:   (n_way * n_query_per_class) labels\n",
    "    \"\"\"\n",
    "    chosen_classes = random.sample(class_names, n_way)\n",
    "    \n",
    "    support_x = []\n",
    "    support_y = []\n",
    "    query_x = []\n",
    "    query_y = []\n",
    "    \n",
    "    for i, cls in enumerate(chosen_classes):\n",
    "        # For each class, randomly sample images\n",
    "        imgs = class_to_imgs_dict[cls]\n",
    "        \n",
    "        chosen_imgs = random.sample(imgs, k_shot + n_query_per_class)\n",
    "        support_paths = chosen_imgs[:k_shot]\n",
    "        query_paths   = chosen_imgs[k_shot:]\n",
    "        \n",
    "        # Load images and store\n",
    "        for sp in support_paths:\n",
    "            support_x.append(load_image(sp))\n",
    "            support_y.append(i)  # label i for this class\n",
    "        for qp in query_paths:\n",
    "            query_x.append(load_image(qp))\n",
    "            query_y.append(i)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    support_x = tf.stack(support_x, axis=0)\n",
    "    support_y = tf.convert_to_tensor(support_y, dtype=tf.int32)\n",
    "    query_x   = tf.stack(query_x, axis=0)\n",
    "    query_y   = tf.convert_to_tensor(query_y, dtype=tf.int32)\n",
    "    \n",
    "    return support_x, support_y, query_x, query_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Embedding Model\n",
    "This function creates an embedding network using a pre-trained ResNet50 as the backbone (with its weights frozen) and adds a global average pooling, dropout, and a dense layer to output a 128-dimensional embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_model(input_shape=(224, 224, 3)):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(128, activation=None)(x)  # 128-dim embedding\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EmbeddingModel\")\n",
    "    return model\n",
    "\n",
    "embedding_model = build_embedding_model((IMG_SIZE, IMG_SIZE, 3))\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Loss Functions and Utility Functions\n",
    "Below are the functions to compute the Euclidean distance and define the contrastive loss for the Siamese network. The `euclidean_distance` function computes the distance between two vectors, while the `contrastive_loss` returns a loss function that is used when compiling the Siamese model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.sqrt(tf.maximum(sum_square, 1e-9))\n",
    "\n",
    "def contrastive_loss(margin=1.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        # y_true is 0 or 1, y_pred is the distance\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square = tf.square(tf.maximum(margin - y_pred, 0.0))\n",
    "        return tf.reduce_mean(\n",
    "            y_true * square_pred + (1 - y_true) * margin_square\n",
    "        )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Siamese (Contrastive) Network\n",
    "This function builds a Siamese network that takes two inputs, processes them via the embedding model, computes their Euclidean distance (via a Lambda layer), and compiles the model using the contrastive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_siamese_network(embedding_model, margin=1.0):\n",
    "    input_a = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"input_a\")\n",
    "    input_b = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"input_b\")\n",
    "    \n",
    "    # Get embeddings\n",
    "    emb_a = embedding_model(input_a)\n",
    "    emb_b = embedding_model(input_b)\n",
    "    \n",
    "    # Distance\n",
    "    distance = layers.Lambda(euclidean_distance, name=\"distance\")([emb_a, emb_b])\n",
    "    \n",
    "    # Build model\n",
    "    siamese_model = tf.keras.Model(inputs=[input_a, input_b], outputs=distance, name=\"SiameseModel\")\n",
    "    \n",
    "    # Compile with contrastive loss\n",
    "    siamese_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=contrastive_loss(margin=margin)\n",
    "    )\n",
    "    \n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Triplet Loss and Building the Triplet Network\n",
    "For the triplet network, we define a custom triplet loss function which ensures that the distance between the anchor and the positive is smaller than the distance between the anchor and the negative by at least a margin. The `build_triplet_network` function creates a model that takes three inputs (anchor, positive, negative), concatenates the embeddings, and compiles the model with the triplet loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(margin=1.0):\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        anchor, positive, negative = tf.split(y_pred, 3, axis=1)\n",
    "        \n",
    "        anchor = tf.squeeze(anchor, axis=1)\n",
    "        positive = tf.squeeze(positive, axis=1)\n",
    "        negative = tf.squeeze(negative, axis=1)\n",
    "        \n",
    "        # Distances\n",
    "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "        \n",
    "        loss_val = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n",
    "        return tf.reduce_mean(loss_val)\n",
    "    return loss\n",
    "\n",
    "def build_triplet_network(embedding_model, margin=1.0):\n",
    "    input_anchor = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"anchor\")\n",
    "    input_pos    = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"positive\")\n",
    "    input_neg    = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"negative\")\n",
    "    \n",
    "    # Embeddings\n",
    "    emb_anchor = embedding_model(input_anchor)\n",
    "    emb_pos    = embedding_model(input_pos)\n",
    "    emb_neg    = embedding_model(input_neg)\n",
    "    \n",
    "    merged = layers.Concatenate(axis=1)([tf.expand_dims(emb_anchor, axis=1),\n",
    "                                         tf.expand_dims(emb_pos, axis=1),\n",
    "                                         tf.expand_dims(emb_neg, axis=1)])\n",
    "    \n",
    "    triplet_model = tf.keras.Model(\n",
    "        inputs=[input_anchor, input_pos, input_neg], \n",
    "        outputs=merged,\n",
    "        name=\"TripletModel\"\n",
    "    )\n",
    "    \n",
    "    triplet_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=triplet_loss(margin=margin)\n",
    "    )\n",
    "    \n",
    "    return triplet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Pairs and Triplets\n",
    "These helper functions generate training data:\n",
    "\n",
    "- **generate_contrastive_pairs:** For each image in the support set, a positive pair (same class) and a negative pair (different class) are generated.\n",
    "- **generate_triplets:** For each anchor image, a positive image (same class) and a negative image (different class) are selected to form a triplet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_contrastive_pairs(support_x, support_y):\n",
    "\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    num_samples = support_x.shape[0]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        anchor = support_x[i]\n",
    "        anchor_label = support_y[i]\n",
    "        \n",
    "        # Positive pair\n",
    "        same_class_indices = tf.where(support_y == anchor_label)\n",
    "        same_class_indices = tf.reshape(same_class_indices, [-1])\n",
    "        same_class_indices = same_class_indices[same_class_indices != i]\n",
    "        if len(same_class_indices) == 0:\n",
    "            continue\n",
    "        pos_idx = np.random.choice(same_class_indices)\n",
    "        \n",
    "        pairs.append((anchor, support_x[pos_idx]))\n",
    "        labels.append(1.0)\n",
    "        \n",
    "        # Negative pair\n",
    "        diff_class_indices = tf.where(support_y != anchor_label)\n",
    "        diff_class_indices = tf.reshape(diff_class_indices, [-1])\n",
    "        neg_idx = np.random.choice(diff_class_indices)\n",
    "        \n",
    "        pairs.append((anchor, support_x[neg_idx]))\n",
    "        labels.append(0.0)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    pairs_a = []\n",
    "    pairs_b = []\n",
    "    for (a, b) in pairs:\n",
    "        pairs_a.append(a.numpy())\n",
    "        pairs_b.append(b.numpy())\n",
    "    \n",
    "    return np.array(pairs_a), np.array(pairs_b), np.array(labels)\n",
    "\n",
    "def generate_triplets(support_x, support_y):\n",
    "    triplets = []\n",
    "    num_samples = support_x.shape[0]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        anchor = support_x[i]\n",
    "        anchor_label = support_y[i]\n",
    "        \n",
    "        # Positive\n",
    "        same_class_indices = tf.where(support_y == anchor_label)\n",
    "        same_class_indices = tf.reshape(same_class_indices, [-1])\n",
    "        same_class_indices = same_class_indices[same_class_indices != i]\n",
    "        if len(same_class_indices) == 0:\n",
    "            continue\n",
    "        pos_idx = np.random.choice(same_class_indices)\n",
    "        \n",
    "        # Negative\n",
    "        diff_class_indices = tf.where(support_y != anchor_label)\n",
    "        diff_class_indices = tf.reshape(diff_class_indices, [-1])\n",
    "        neg_idx = np.random.choice(diff_class_indices)\n",
    "        \n",
    "        triplets.append((anchor, support_x[pos_idx], support_x[neg_idx]))\n",
    "    \n",
    "    # Convert to arrays\n",
    "    anchors, positives, negatives = [], [], []\n",
    "    for (a, p, n) in triplets:\n",
    "        anchors.append(a.numpy())\n",
    "        positives.append(p.numpy())\n",
    "        negatives.append(n.numpy())\n",
    "    \n",
    "    return np.array(anchors), np.array(positives), np.array(negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Siamese (Contrastive) Network\n",
    "The following cell demonstrates how to generate an episode, create contrastive pairs, and then train the Siamese network over several episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAY = 3\n",
    "K_SHOT = 3\n",
    "N_QUERY = 4\n",
    "\n",
    "embedding_model = build_embedding_model((IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "# ====  Contrastive (Siamese) Example ====\n",
    "siamese_model = build_siamese_network(embedding_model, margin=1.0)\n",
    "\n",
    "for episode in range(20):\n",
    "    # Create an episode\n",
    "    support_x, support_y, query_x, query_y = create_episode(\n",
    "        class_to_imgs_dict=class_to_images,\n",
    "        class_names=class_names,\n",
    "        n_way=N_WAY,\n",
    "        k_shot=K_SHOT,\n",
    "        n_query_per_class=N_QUERY\n",
    "    )\n",
    "    \n",
    "    X_a, X_b, y_pairs = generate_contrastive_pairs(support_x, support_y)\n",
    "    \n",
    "    siamese_model.fit(\n",
    "        x=[X_a, X_b],\n",
    "        y=y_pairs,\n",
    "        batch_size=4,\n",
    "        epochs=2,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Triplet Network\n",
    "In this cell, we generate triplets (anchor, positive, negative) and train the triplet network with the custom triplet loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Triplet Example ====\n",
    "embedding_model_2 = build_embedding_model((IMG_SIZE, IMG_SIZE, 3))\n",
    "triplet_model = build_triplet_network(embedding_model_2, margin=1.0)\n",
    "\n",
    "for episode in range(20):\n",
    "    support_x, support_y, query_x, query_y = create_episode(\n",
    "        class_to_imgs_dict=class_to_images,\n",
    "        class_names=class_names,\n",
    "        n_way=N_WAY,\n",
    "        k_shot=K_SHOT,\n",
    "        n_query_per_class=N_QUERY\n",
    "    )\n",
    "    \n",
    "    anchors, positives, negatives = generate_triplets(support_x, support_y)\n",
    "    \n",
    "    dummy_y = np.zeros((anchors.shape[0],))\n",
    "    \n",
    "    triplet_model.fit(\n",
    "        x=[anchors, positives, negatives],\n",
    "        y=dummy_y,\n",
    "        batch_size=4,\n",
    "        epochs=2,\n",
    "        verbose=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
